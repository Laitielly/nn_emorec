{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T05:37:44.875134Z",
     "iopub.status.busy": "2024-02-20T05:37:44.874711Z",
     "iopub.status.idle": "2024-02-20T05:37:49.226295Z",
     "shell.execute_reply": "2024-02-20T05:37:49.225491Z",
     "shell.execute_reply.started": "2024-02-20T05:37:44.875109Z"
    }
   },
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.pytorch import log_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T05:37:44.275458Z",
     "iopub.status.busy": "2024-02-20T05:37:44.275143Z",
     "iopub.status.idle": "2024-02-20T05:37:44.873569Z",
     "shell.execute_reply": "2024-02-20T05:37:44.872756Z",
     "shell.execute_reply.started": "2024-02-20T05:37:44.275428Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T05:37:49.229613Z",
     "iopub.status.busy": "2024-02-20T05:37:49.228953Z",
     "iopub.status.idle": "2024-02-20T05:37:49.234015Z",
     "shell.execute_reply": "2024-02-20T05:37:49.233138Z",
     "shell.execute_reply.started": "2024-02-20T05:37:49.229579Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T05:37:49.235656Z",
     "iopub.status.busy": "2024-02-20T05:37:49.235337Z",
     "iopub.status.idle": "2024-02-20T05:41:43.885985Z",
     "shell.execute_reply": "2024-02-20T05:41:43.885010Z",
     "shell.execute_reply.started": "2024-02-20T05:37:49.235625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2941546\n"
     ]
    }
   ],
   "source": [
    "with open('fea_notebooks/features_newvf2.pickle', 'rb') as handle:\n",
    "    data=pickle.load(handle)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T05:41:43.887699Z",
     "iopub.status.busy": "2024-02-20T05:41:43.887344Z",
     "iopub.status.idle": "2024-02-20T05:41:43.943929Z",
     "shell.execute_reply": "2024-02-20T05:41:43.943079Z",
     "shell.execute_reply.started": "2024-02-20T05:41:43.887667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.0.1+cu118\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Torch: {torch.__version__}\")\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action Unit Detection\n",
    "## Get target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T05:41:50.191261Z",
     "iopub.status.busy": "2024-02-20T05:41:50.190550Z",
     "iopub.status.idle": "2024-02-20T05:41:50.196839Z",
     "shell.execute_reply": "2024-02-20T05:41:50.195801Z",
     "shell.execute_reply.started": "2024-02-20T05:41:50.191226Z"
    }
   },
   "outputs": [],
   "source": [
    "idx_to_class_2={0: 'Neutral', 1:'Anger', 2:'Disgust', 3:'Fear', \n",
    "                4:'Happiness', 5:'Sadness', 6:'Surprise', 7:'Other'} #ABAW\n",
    "classes = ['Neutral', 'Anger', 'Disgust', 'Fear', \n",
    "           'Happiness', 'Sadness', 'Surprise', 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T05:41:50.198725Z",
     "iopub.status.busy": "2024-02-20T05:41:50.198027Z",
     "iopub.status.idle": "2024-02-20T05:41:54.354176Z",
     "shell.execute_reply": "2024-02-20T05:41:54.353109Z",
     "shell.execute_reply.started": "2024-02-20T05:41:50.198698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336508 23015\n",
      "445845 0\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = '/home/HDD6TB/datasets/emotions/ABAW/ABAW_6/6th_ABAW_Annotations'\n",
    "\n",
    "def get_image2Expr(dirname):\n",
    "    dirpath=os.path.join(DATA_DIR,'AU_Detection_Challenge/',dirname)\n",
    "    num_missed=[]\n",
    "    targets = {}\n",
    "    folders = []\n",
    "    for filename in os.listdir(dirpath):\n",
    "        fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "        fn_short=fn\n",
    "        if fn.endswith('_left'):\n",
    "            fn_short=fn[:-5]\n",
    "        elif fn.endswith('_right'):\n",
    "            fn_short=fn[:-6]\n",
    "    \n",
    "        if ext.lower()=='.txt':\n",
    "            folders.append(fn)\n",
    "            with open(os.path.join(dirpath,filename)) as f:\n",
    "                lines = f.read().splitlines()\n",
    "                for i,line in enumerate(lines):\n",
    "                    if i>0:\n",
    "                        splitted_line=line.split(',')\n",
    "                        aus=list(map(int,splitted_line))\n",
    "                        if min(aus)>=0:\n",
    "                            imagename_short=fn_short+'/'+str(i).zfill(5)+'.jpg'\n",
    "                            imagename=fn+'/'+str(i).zfill(5)+'.jpg'\n",
    "                            has_image=imagename_short in data\n",
    "                            \n",
    "                            if dirname=='Validation_Set':\n",
    "                                has_frame=os.path.exists(os.path.join(DATA_DIR,\n",
    "                                                                      'cropped_aligned/cropped_aligned',\n",
    "                                                                      imagename))\n",
    "                                has_frame=has_frame or os.path.exists(os.path.join(DATA_DIR,\n",
    "                                                                    'cropped_aligned/cropped_aligned_new_50_vids',\n",
    "                                                                                   imagename))\n",
    "                                if has_image:\n",
    "                                    has_image=has_frame\n",
    "                                elif has_frame:\n",
    "                                    imagename=fn_short+'/'+get_names(i-1)+'.jpg'\n",
    "                                    has_image=imagename in data\n",
    "                                    \n",
    "                            if has_image:\n",
    "                                targets[imagename] = aus\n",
    "                            else:\n",
    "                                num_missed.append(imagename)\n",
    "                            \n",
    "                        \n",
    "    print(len(targets), len(num_missed))\n",
    "    return targets, num_missed, folders\n",
    "\n",
    "y_train, num_missed_train, train_f = get_image2Expr('Train_Set')\n",
    "y_val, num_missed_test, val_f =get_image2Expr('Validation_Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get train samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T05:41:43.945157Z",
     "iopub.status.busy": "2024-02-20T05:41:43.944909Z",
     "iopub.status.idle": "2024-02-20T05:41:50.188934Z",
     "shell.execute_reply": "2024-02-20T05:41:50.187801Z",
     "shell.execute_reply.started": "2024-02-20T05:41:43.945135Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/home/hse_student/apsidorova' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/annanet/abaw6/ae2ed106d039429fa7201980d5a6d1b3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(\n",
    "  api_key=\"XhQqrLR91F7zW3AZ7LgVT3zp2\",\n",
    "  project_name=\"abaw6\",\n",
    "  workspace=\"annanet\"\n",
    ")\n",
    "\n",
    "experiment.set_name('au-tcn_attention+only_vid')\n",
    "experiment.add_tags(['au_classif_tcn - tcn_attention+only_vid', 'v2_tcn+only_vid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336508 0 0 0 1336508 445845 0 0 0 445845\n"
     ]
    }
   ],
   "source": [
    "def train_val_split(y_train, y_val):\n",
    "    w2v2large_t, openl3_t, w2v2hub_t, y_t = \\\n",
    "    [], [], [], []\n",
    "    X_t, X_v = [], []\n",
    "    for key in y_train.keys():\n",
    "        X_t.append(data[key]['frame'][0])\n",
    "        y_t.append(y_train[key])\n",
    "\n",
    "    w2v2large_v, openl3_v, w2v2hub_v, y_v = \\\n",
    "    [], [], [], []\n",
    "    \n",
    "    for key in y_val.keys():\n",
    "        X_v.append(data[key]['frame'][0])\n",
    "        y_v.append(y_val[key])\n",
    "\n",
    "    print(len(X_t), len(w2v2large_t), len(openl3_t), len(w2v2hub_t), len(y_t),\n",
    "          len(X_v), len(w2v2large_v), len(openl3_v), len(w2v2hub_v), len(y_v))\n",
    "    \n",
    "    return (np.array(X_t),np.array(w2v2large_t), \n",
    "            np.array(openl3_t), np.array(w2v2hub_t), \n",
    "            np.array(y_t),\n",
    "            np.array(X_v), np.array(w2v2large_v), \n",
    "            np.array(openl3_v), np.array(w2v2hub_v), \n",
    "            np.array(y_v))\n",
    "\n",
    "X_t, w2v2large_t, openl3_t, w2v2hub_t, y_t, \\\n",
    "X_v, w2v2large_v, openl3_v, w2v2hub_v, y_v = train_val_split(y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "\n",
    "class audioDataset(Dataset):\n",
    "    def __init__(self, names, values, y, window=300, step=200):\n",
    "        self.data = values\n",
    "        self.lenghts_of_seq = len(self.data[0])\n",
    "        self.y = y\n",
    "        \n",
    "        self.names = names\n",
    "        self.window = window\n",
    "        self.step = step\n",
    "        \n",
    "        self.len = ceil((self.lenghts_of_seq - self.window) / self.step) + 1\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx == self.len-1:\n",
    "            stride = [torch.from_numpy(i[-self.window::]) for i in self.data]\n",
    "            y = self.y[-self.window::]\n",
    "        \n",
    "        else:\n",
    "            stride = [torch.from_numpy(i[idx*self.step:idx*self.step + self.window]) for i in self.data]\n",
    "            y = self.y[idx*self.step:idx*self.step + self.window]\n",
    "            \n",
    "        r_dict = dict([(i, j.to(device)) for i, j in zip(self.names, stride)])\n",
    "        \n",
    "        return r_dict, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "taudio = audioDataset(['frames'],\n",
    "                     [X_t], y_t)\n",
    "training_loader = DataLoader(taudio, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1487, 24)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaudio = audioDataset(['frames'],\n",
    "                     [X_v], y_v,\n",
    "                     window=300, step=300)\n",
    "validation_loader = DataLoader(vaudio, batch_size=64, shuffle=False)\n",
    "len(vaudio), len(validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "[[ 0.5676408   4.19599397]\n",
      " [ 0.52621781 10.03550136]\n",
      " [ 0.58741717  3.35984997]\n",
      " [ 0.67448898  1.93275527]\n",
      " [ 0.82961596  1.25845841]\n",
      " [ 0.76377734  1.44776905]\n",
      " [ 0.66014022  2.0611319 ]\n",
      " [ 0.51432323 17.95416443]\n",
      " [ 0.51636598 15.77559018]\n",
      " [ 0.51306002 19.64239734]\n",
      " [ 1.33713913  0.79863614]\n",
      " [ 0.54020709  6.71780849]]\n"
     ]
    }
   ],
   "source": [
    "num_labels=y_t.shape[1]\n",
    "print(num_labels)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = np.empty([num_labels, 2])\n",
    "for i in range(num_labels):\n",
    "    neg, pos = np.bincount(y_t[:, i])\n",
    "    total = neg + pos\n",
    "    weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "    weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "    class_weights[i][0]=weight_for_0\n",
    "    class_weights[i][1]=weight_for_1\n",
    "    #class_weights[i] = compute_class_weight('balanced', [0,1], y_train[:, i])\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcn import TemporalConvNet\n",
    "from trans_encoder import TransEncoder\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, modality=['frames', 'w2v2large', 'openl3', 'w2v2hub'],\n",
    "                 embedding_dim={'frames': 1280, 'w2v2large': 1024, 'openl3': 512,\n",
    "                                'w2v2hub': 256},\n",
    "                 tcn_channel={\n",
    "                     'frames': [1280, 512, 256, 128],\n",
    "                     'w2v2large': [1024, 512, 256, 128],\n",
    "                     'openl3': [512, 256, 128],\n",
    "                     'w2v2hub': [256, 128]\n",
    "    }):\n",
    "        super(Model, self).__init__()\n",
    "        self.modality = modality\n",
    "\n",
    "        self.temporal, self.fusion = nn.ModuleDict(), None\n",
    "\n",
    "        for modal in self.modality:\n",
    "            self.temporal[modal] = TemporalConvNet(num_inputs=embedding_dim[modal],\n",
    "                                                   num_channels=tcn_channel[modal], dropout=0.3, attention=False)\n",
    "\n",
    "        conv_dim = 0\n",
    "        for m in self.modality:\n",
    "            conv_dim += tcn_channel[m][-1]\n",
    "            \n",
    "        self.encoder = TransEncoder(\n",
    "            inc=conv_dim, outc=256, dropout=0.3, nheads=4, \n",
    "            nlayer=8)\n",
    "            \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(256, 256//2),\n",
    "            nn.BatchNorm1d(256//2),\n",
    "            nn.Linear(256//2, 12),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        bs, seq_len, _ = x[self.modality[0]].shape\n",
    "#         print(bs, seq_len)\n",
    "        for m in self.modality:\n",
    "            x[m] = x[m].transpose(1, 2)\n",
    "            x[m] = self.temporal[m](x[m])\n",
    "\n",
    "        feat_list = []\n",
    "        for m in self.modality:\n",
    "            feat_list.append(x[m])\n",
    "        out = torch.cat(feat_list, dim=1)\n",
    "        out = self.encoder(out)\n",
    "\n",
    "        out = torch.transpose(out, 1, 0)\n",
    "        out = torch.reshape(out, (bs*seq_len, -1))\n",
    "#         print(out.shape)\n",
    "\n",
    "        out = self.head(out)\n",
    "        return F.sigmoid(out)\n",
    "\n",
    "model = Model(modality=['frames'], embedding_dim={'frames': 1280},\n",
    "              tcn_channel={\n",
    "                     'frames': [1280, 512, 256, 128]})\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'epochs': 100,\n",
    "    'loss': 'categorical_crossentropy',\n",
    "    'lr': 1e-4,\n",
    "    'batch': 64\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [0.04926029 0.11781515 0.03944409 0.02269023 0.0147741  0.01699657\n",
      " 0.02419735 0.21077897 0.18520286 0.23059855 0.00937586 0.07886598]\n"
     ]
    }
   ],
   "source": [
    "class_frequencies = y_t.sum(axis=0)  # Example class frequencies\n",
    "\n",
    "# Compute class weights\n",
    "total_samples = np.sum(class_frequencies)\n",
    "class_weights = total_samples / (len(class_frequencies) * class_frequencies)\n",
    "\n",
    "# Normalize the weights\n",
    "normalized_weights = class_weights / np.sum(class_weights)\n",
    "print(\"Class Weights:\", normalized_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.log_parameters(hyperparams)\n",
    "\n",
    "loss_fn = nn.BCELoss(weight=torch.Tensor(normalized_weights)).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=hyperparams['lr'])\n",
    "\n",
    "best_model_params = deepcopy(model.state_dict())\n",
    "\n",
    "best_vloss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 1.0581288025356257 valid 0.054938580840826035, f1_valid 0.4203890406070508\n",
      "EPOCH 2:\n",
      "LOSS train 1.0555026049797351 valid 0.052813004702329636, f1_valid 0.45734813269999064\n",
      "EPOCH 3:\n",
      "LOSS train 1.0532442908734083 valid 0.052626147866249084, f1_valid 0.45378812383079886\n",
      "EPOCH 4:\n",
      "LOSS train 1.0507661618578892 valid 0.05199640616774559, f1_valid 0.46491715382829835\n",
      "EPOCH 5:\n",
      "LOSS train 1.0475232141952102 valid 0.04940766096115112, f1_valid 0.47945981018257156\n",
      "EPOCH 6:\n",
      "LOSS train 1.0437838695585155 valid 0.04869481548666954, f1_valid 0.38035818078821565\n",
      "EPOCH 7:\n",
      "LOSS train 1.0399187770672143 valid 0.04167936369776726, f1_valid 0.47671726715438895\n",
      "EPOCH 8:\n",
      "LOSS train 1.0351738707663922 valid 0.03583599999547005, f1_valid 0.4762320873938961\n",
      "EPOCH 9:\n",
      "LOSS train 1.03093066596641 valid 0.031756747514009476, f1_valid 0.45533031652625433\n",
      "EPOCH 10:\n",
      "LOSS train 1.0273200672370597 valid 0.027871619910001755, f1_valid 0.4642095540545541\n",
      "EPOCH 11:\n",
      "LOSS train 1.0241816272565092 valid 0.02631464973092079, f1_valid 0.46884557875489424\n",
      "EPOCH 12:\n",
      "LOSS train 1.0216799054760486 valid 0.02407117187976837, f1_valid 0.4750713458477695\n",
      "EPOCH 13:\n",
      "LOSS train 1.0197337397929425 valid 0.022332072257995605, f1_valid 0.4651360480810906\n",
      "EPOCH 14:\n",
      "LOSS train 1.0181157734567443 valid 0.022504083812236786, f1_valid 0.4582741133471578\n",
      "EPOCH 15:\n",
      "LOSS train 1.0167911627795547 valid 0.020533308386802673, f1_valid 0.48140766906142796\n",
      "EPOCH 16:\n",
      "LOSS train 1.0156716778874397 valid 0.020518764853477478, f1_valid 0.4908153522003305\n",
      "EPOCH 17:\n",
      "LOSS train 1.0147424001479521 valid 0.018759416416287422, f1_valid 0.4950176919451868\n",
      "EPOCH 18:\n",
      "LOSS train 1.0139310272732893 valid 0.01943923532962799, f1_valid 0.4826722277227357\n",
      "EPOCH 19:\n",
      "LOSS train 1.0132556792008331 valid 0.017894580960273743, f1_valid 0.4783589638704102\n",
      "EPOCH 20:\n",
      "LOSS train 1.0127912699468793 valid 0.01774388924241066, f1_valid 0.49685449901319734\n",
      "EPOCH 21:\n",
      "LOSS train 1.0124170962058439 valid 0.017419366165995598, f1_valid 0.4867847272322358\n",
      "EPOCH 22:\n",
      "LOSS train 1.0119964109438184 valid 0.017701182514429092, f1_valid 0.49806774244704766\n",
      "EPOCH 23:\n",
      "LOSS train 1.0116808646170494 valid 0.016793498769402504, f1_valid 0.4806018637780101\n",
      "EPOCH 24:\n",
      "LOSS train 1.0113407673958976 valid 0.016201453283429146, f1_valid 0.4711436671823295\n",
      "EPOCH 25:\n",
      "LOSS train 1.0109158181674922 valid 0.017722634598612785, f1_valid 0.5052053938947588\n",
      "EPOCH 26:\n",
      "LOSS train 1.0107893369277008 valid 0.016255976632237434, f1_valid 0.47487373953108586\n",
      "EPOCH 27:\n",
      "LOSS train 1.0104367157865244 valid 0.01682339608669281, f1_valid 0.501693109429652\n",
      "EPOCH 28:\n",
      "LOSS train 1.0104304369933044 valid 0.016712848097085953, f1_valid 0.5029872962140288\n",
      "EPOCH 29:\n",
      "LOSS train 1.01031834897227 valid 0.01738458126783371, f1_valid 0.5150335197173357\n",
      "EPOCH 30:\n",
      "LOSS train 1.010573479897665 valid 0.017515262588858604, f1_valid 0.5100179008088112\n",
      "EPOCH 31:\n",
      "LOSS train 1.0100795802696108 valid 0.01646406576037407, f1_valid 0.5048277815682173\n",
      "EPOCH 32:\n",
      "LOSS train 1.0098183596005232 valid 0.01616896688938141, f1_valid 0.4726443821842821\n",
      "EPOCH 33:\n",
      "LOSS train 1.0096860343160539 valid 0.016342606395483017, f1_valid 0.4961237638512652\n",
      "EPOCH 34:\n",
      "LOSS train 1.0094031564389856 valid 0.01630738005042076, f1_valid 0.5062529175406526\n",
      "EPOCH 35:\n",
      "LOSS train 1.0092555314320355 valid 0.016075514256954193, f1_valid 0.47091933560543214\n",
      "EPOCH 36:\n",
      "LOSS train 1.0090100515427856 valid 0.01642286404967308, f1_valid 0.5090397862874382\n",
      "EPOCH 37:\n",
      "LOSS train 1.0088185117436717 valid 0.01683131605386734, f1_valid 0.5113767786642424\n",
      "EPOCH 38:\n",
      "LOSS train 1.0087532805090842 valid 0.016903072595596313, f1_valid 0.5142493935438025\n",
      "EPOCH 39:\n",
      "LOSS train 1.0089455924081938 valid 0.016520053148269653, f1_valid 0.49362833298349273\n",
      "EPOCH 40:\n",
      "LOSS train 1.0093634775414382 valid 0.020524010062217712, f1_valid 0.5035757635535355\n",
      "EPOCH 41:\n",
      "LOSS train 1.0089097664928817 valid 0.016506370157003403, f1_valid 0.4763155136173685\n",
      "EPOCH 42:\n",
      "LOSS train 1.008654971170472 valid 0.01916097290813923, f1_valid 0.5192760491354317\n",
      "EPOCH 43:\n",
      "LOSS train 1.0084822063911885 valid 0.016533199697732925, f1_valid 0.4955606040936504\n",
      "EPOCH 44:\n",
      "LOSS train 1.0083344940414043 valid 0.017089013010263443, f1_valid 0.5222507000661599\n",
      "EPOCH 45:\n",
      "LOSS train 1.0081672345382127 valid 0.017203237861394882, f1_valid 0.4933188268252495\n",
      "EPOCH 46:\n",
      "LOSS train 1.007951119959426 valid 0.017264951020479202, f1_valid 0.48894028916512283\n",
      "EPOCH 47:\n",
      "LOSS train 1.007877334699375 valid 0.016995050013065338, f1_valid 0.5105996667637546\n",
      "EPOCH 48:\n",
      "LOSS train 1.0078599813680809 valid 0.01712406985461712, f1_valid 0.48618752974070073\n",
      "EPOCH 49:\n",
      "LOSS train 1.0077716596267867 valid 0.018164053559303284, f1_valid 0.501761814139908\n",
      "EPOCH 50:\n",
      "LOSS train 1.0078385806767842 valid 0.01702248305082321, f1_valid 0.4996942414553633\n",
      "EPOCH 51:\n",
      "LOSS train 1.0076407865182353 valid 0.018823787569999695, f1_valid 0.48721324969217056\n",
      "EPOCH 52:\n",
      "LOSS train 1.0075803728272708 valid 0.01801716350018978, f1_valid 0.4950845091193263\n",
      "EPOCH 53:\n",
      "LOSS train 1.0075384882690672 valid 0.017843980342149734, f1_valid 0.5042767423565748\n",
      "EPOCH 54:\n",
      "LOSS train 1.0074580744907367 valid 0.017987553030252457, f1_valid 0.5139075634582487\n",
      "EPOCH 55:\n",
      "LOSS train 1.0073142970594255 valid 0.017493702471256256, f1_valid 0.5092041938777332\n",
      "EPOCH 56:\n",
      "LOSS train 1.0072636181788626 valid 0.018816597759723663, f1_valid 0.5163068699706395\n",
      "EPOCH 57:\n",
      "LOSS train 1.007221876507034 valid 0.01862616091966629, f1_valid 0.5038416181526476\n",
      "EPOCH 58:\n",
      "LOSS train 1.0071530632692605 valid 0.01907457783818245, f1_valid 0.509925730011188\n",
      "EPOCH 59:\n",
      "LOSS train 1.0072435949270864 valid 0.018499251455068588, f1_valid 0.5063246705923693\n",
      "EPOCH 60:\n",
      "LOSS train 1.0071517073285157 valid 0.017329059541225433, f1_valid 0.5092798961294595\n",
      "EPOCH 61:\n",
      "LOSS train 1.0069562867597246 valid 0.018401972949504852, f1_valid 0.5123177867454294\n",
      "EPOCH 62:\n",
      "LOSS train 1.00674900949861 valid 0.01956428587436676, f1_valid 0.5249778203411767\n",
      "EPOCH 63:\n",
      "LOSS train 1.0067970402104458 valid 0.018367335200309753, f1_valid 0.502507000997609\n",
      "EPOCH 64:\n",
      "LOSS train 1.0066800571042291 valid 0.018691767007112503, f1_valid 0.5197367488729039\n",
      "EPOCH 65:\n",
      "LOSS train 1.0064960424071894 valid 0.018484486266970634, f1_valid 0.4893642689135605\n",
      "EPOCH 66:\n",
      "LOSS train 1.0064367575866457 valid 0.019132867455482483, f1_valid 0.5099247177485864\n",
      "EPOCH 67:\n",
      "LOSS train 1.0065334523544431 valid 0.018302258104085922, f1_valid 0.5106754978322168\n",
      "EPOCH 68:\n",
      "LOSS train 1.0066292517317028 valid 0.02048545703291893, f1_valid 0.514370931874483\n",
      "EPOCH 69:\n",
      "LOSS train 1.0066547908421712 valid 0.01844729296863079, f1_valid 0.5074434077544523\n",
      "EPOCH 70:\n",
      "LOSS train 1.0064784047269943 valid 0.01918979361653328, f1_valid 0.5133905624677292\n",
      "EPOCH 71:\n",
      "LOSS train 1.0063352876280147 valid 0.018908880650997162, f1_valid 0.5127044229151388\n",
      "EPOCH 72:\n",
      "LOSS train 1.0063319612146677 valid 0.018834887072443962, f1_valid 0.4987205166724096\n",
      "EPOCH 73:\n",
      "LOSS train 1.0062035835200311 valid 0.01956595480442047, f1_valid 0.5040929422787533\n",
      "EPOCH 74:\n",
      "LOSS train 1.006194732541469 valid 0.019990820437669754, f1_valid 0.5084085247077087\n",
      "EPOCH 75:\n",
      "LOSS train 1.0061386134318757 valid 0.019987711682915688, f1_valid 0.5113420603143176\n",
      "EPOCH 76:\n",
      "LOSS train 1.005984328376004 valid 0.02091035805642605, f1_valid 0.48254396089993085\n",
      "EPOCH 77:\n",
      "LOSS train 1.0059338382740792 valid 0.019487056881189346, f1_valid 0.51297055929984\n",
      "EPOCH 78:\n",
      "LOSS train 1.0058187930396973 valid 0.020328234881162643, f1_valid 0.500865437193112\n",
      "EPOCH 79:\n",
      "LOSS train 1.0058071316072108 valid 0.0190895888954401, f1_valid 0.5030775181670075\n",
      "EPOCH 80:\n",
      "LOSS train 1.0056998241164434 valid 0.021186649799346924, f1_valid 0.5143970726982913\n",
      "EPOCH 81:\n",
      "LOSS train 1.0057241272320074 valid 0.0196896493434906, f1_valid 0.4810848362127516\n",
      "EPOCH 82:\n",
      "LOSS train 1.0058007951346764 valid 0.021201757714152336, f1_valid 0.5078581020230079\n",
      "EPOCH 83:\n",
      "LOSS train 1.0057527495104854 valid 0.019719937816262245, f1_valid 0.49226079372051107\n",
      "EPOCH 84:\n",
      "LOSS train 1.005645452277699 valid 0.021768396720290184, f1_valid 0.520201142749558\n",
      "EPOCH 85:\n",
      "LOSS train 1.00561011317992 valid 0.02151491306722164, f1_valid 0.5081064174736597\n",
      "EPOCH 86:\n",
      "LOSS train 1.0055952252520142 valid 0.02254600077867508, f1_valid 0.5090753862941274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 87:\n",
      "LOSS train 1.0056376429364229 valid 0.020360615104436874, f1_valid 0.5004861708402742\n",
      "EPOCH 88:\n",
      "LOSS train 1.0067766384163406 valid 0.021262196823954582, f1_valid 0.5170883036005421\n",
      "EPOCH 89:\n",
      "LOSS train 1.0062005240917922 valid 0.01980806514620781, f1_valid 0.5049342348412177\n",
      "EPOCH 90:\n",
      "LOSS train 1.0063066433918162 valid 0.021143442019820213, f1_valid 0.49932607324861183\n",
      "EPOCH 91:\n",
      "LOSS train 1.005685668483448 valid 0.021048245951533318, f1_valid 0.5163708483738879\n",
      "EPOCH 92:\n",
      "LOSS train 1.0053922819385592 valid 0.020866943523287773, f1_valid 0.5209084849642078\n",
      "EPOCH 93:\n",
      "LOSS train 1.0051987042780428 valid 0.02161431312561035, f1_valid 0.5104129010186609\n",
      "EPOCH 94:\n",
      "LOSS train 1.0051621683568766 valid 0.020858921110630035, f1_valid 0.5127444748104263\n",
      "EPOCH 95:\n",
      "LOSS train 1.0050634474430877 valid 0.021566763520240784, f1_valid 0.4947461244526925\n",
      "EPOCH 96:\n",
      "LOSS train 1.0049856732948683 valid 0.021650217473506927, f1_valid 0.4964087180875594\n",
      "EPOCH 97:\n",
      "LOSS train 1.0050155714673634 valid 0.021936725825071335, f1_valid 0.5081415426346936\n",
      "EPOCH 98:\n",
      "LOSS train 1.005032776812396 valid 0.02133314311504364, f1_valid 0.5151830465838703\n",
      "EPOCH 99:\n",
      "LOSS train 1.0049853353188014 valid 0.02276800200343132, f1_valid 0.5138998816956153\n",
      "EPOCH 100:\n",
      "LOSS train 1.004955767785969 valid 0.023290906101465225, f1_valid 0.48524909932899485\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(hyperparams['epochs']):\n",
    "    print('EPOCH {}:'.format(epoch + 1))\n",
    "    pred_labels_train, pred_labels_val = [], []\n",
    "    labels_train, labels_val = [], []\n",
    "\n",
    "    model.train(True)\n",
    "    \n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    for i, tdata in enumerate(training_loader):\n",
    "        inputs, labels = tdata\n",
    "#         print(labels.shape)\n",
    "        labels = labels.reshape(labels.shape[0]*labels.shape[1], 12).to(device).to(torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs).to(torch.float32)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        predicted = outputs >= 0.5\n",
    "        pred_labels_train += predicted.tolist()\n",
    "        labels_train += labels.tolist()\n",
    "        \n",
    "        del tdata\n",
    "        del inputs\n",
    "        del labels\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    avg_loss = running_loss / i + 1\n",
    "    experiment.log_metric('loss_train', avg_loss, \n",
    "                          epoch=epoch)\n",
    "    \n",
    "    running_vloss = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            vlabels = vlabels.reshape(vlabels.shape[0]*vlabels.shape[1], 12).to(device).to(torch.float32)\n",
    "            voutputs = model(vinputs).to(torch.float32)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "            \n",
    "            predicted = voutputs >= 0.5\n",
    "            pred_labels_val += predicted.tolist()\n",
    "            labels_val += vlabels.tolist()\n",
    "            \n",
    "            del vinputs\n",
    "            del vlabels\n",
    "            del vdata\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    val_f1 = f1_score(labels_val,\n",
    "                      pred_labels_val,\n",
    "                      average='macro')\n",
    "    print('LOSS train {} valid {}, f1_valid {}'.format(avg_loss, avg_vloss, val_f1))\n",
    "    experiment.log_metric('loss_val', avg_vloss, \n",
    "                          epoch=epoch)\n",
    "    experiment.log_metric('f1_val', f1_score(labels_val,\n",
    "                                             pred_labels_val,\n",
    "                                             average='macro'), \n",
    "                          epoch=epoch)\n",
    "    experiment.log_metric('f1_train', f1_score(labels_train,\n",
    "                                               pred_labels_train,\n",
    "                                               average='macro'), \n",
    "                          epoch=epoch)\n",
    "    \n",
    "    if val_f1 > best_vloss:\n",
    "        best_vloss = val_f1\n",
    "        best_model_params = deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:02<00:00,  8.72it/s]\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(best_model_params)\n",
    "pred_labels_val, labels_val = [], []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, vdata in enumerate(tqdm(validation_loader)):\n",
    "        vinputs, vlabels = vdata\n",
    "        vlabels = vlabels.reshape(vlabels.shape[0]*vlabels.shape[1], 12).to(device).to(torch.float32)\n",
    "        voutputs = model(vinputs).to(torch.float32)\n",
    "\n",
    "        predicted = voutputs >= 0.5\n",
    "        pred_labels_val += predicted.tolist()\n",
    "        labels_val += vlabels.tolist()\n",
    "\n",
    "        del vinputs\n",
    "        del vlabels\n",
    "        del vdata\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(labels_val,\n",
    "        pred_labels_val,\n",
    "        average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8827109018904581"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(labels_val)==np.array(pred_labels_val)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5249778203411767"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'web': 'https://www.comet.com/api/asset/download?assetId=cb423bac2950493eb150968b644a2d88&experimentKey=ae2ed106d039429fa7201980d5a6d1b3',\n",
       " 'api': 'https://www.comet.com/api/rest/v2/experiment/asset/get-asset?assetId=cb423bac2950493eb150968b644a2d88&experimentKey=ae2ed106d039429fa7201980d5a6d1b3',\n",
       " 'assetId': 'cb423bac2950493eb150968b644a2d88'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'simplemodel.pt')\n",
    "experiment.log_model(\"simplemodel.pt\", file_or_folder=\"simplemodel.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/annanet/abaw6/ae2ed106d039429fa7201980d5a6d1b3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     f1_train [100]   : (0.3215614208145707, 0.8368070894883383)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     f1_val [100]     : (0.38035818078821565, 0.5249778203411767)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [1050]      : (0.001998973311856389, 0.061403483152389526)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss_train [100] : (1.004955767785969, 1.0581288025356257)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss_val [100]   : (0.016075514256954193, 0.054938580840826035)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : au-tcn_attention+only_vid\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch  : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss   : categorical_crossentropy\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr     : 0.0001\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 1 (49.44 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 file(s), remaining 46.44 MB/49.44 MB\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m All assets have been sent, waiting for delivery confirmation\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4438302,
     "sourceId": 7648578,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
